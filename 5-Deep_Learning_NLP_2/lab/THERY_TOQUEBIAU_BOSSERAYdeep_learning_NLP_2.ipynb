{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EsQI2YK0ycXi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IrqOXKU5ycXo"
   },
   "source": [
    "This is an introduction to basic sequence-to-sequence learning using a Long short term memory (LSTM) module.\n",
    "Given a string of characters representing a math problem \"3141+42\" we would like to generate a string of characters representing the correct solution: \"3183\". Our network will learn how to do basic mathematical operations.\n",
    "The important part is that we will not first use our human intelligence to break the string up into integers and a mathematical operator. We want the computer to figure all that out by itself.\n",
    "Each math problem is an input sequence: a list of {0,...,9} integers and math operation symbols\n",
    "The result of the operation (\"$3141+42$\" $\\rightarrow$ \"$3183$\"</span>) is the sequence to decode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKUyd15mycXr"
   },
   "source": [
    "**math_operators** is the set of $5$ operations we are going to use to build are input sequences.<br/>\n",
    "The math_expressions_generation function uses them to generate a large set of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BdnM8_wrycXs"
   },
   "outputs": [],
   "source": [
    "\n",
    "def math_expressions_generation(n_samples=1000, n_digits=3, invert=True):\n",
    "    X, Y = [], []\n",
    "    math_operators = {\n",
    "        \"+\": operator.add,\n",
    "        \"-\": operator.sub,\n",
    "        \"*\": operator.mul,\n",
    "        \"/\": operator.truediv,\n",
    "        \"%\": operator.mod,\n",
    "    }\n",
    "    for i in range(n_samples):\n",
    "        a, b = np.random.randint(1, 10 ** n_digits, size=2)\n",
    "        op = np.random.choice(list(math_operators.keys()))\n",
    "        res = math_operators[op](a, b)\n",
    "        x = \"\".join([str(elem) for elem in (a, op, b)])\n",
    "        if invert is True:\n",
    "            x = x[::-1]\n",
    "        y = \"{:.5f}\".format(res) if isinstance(res, float) else str(res)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "colab_type": "code",
    "id": "h7RNeQaIycXx",
    "outputId": "a0add80b-8d04-47a3-b6a5-1df8b67fc6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902+994 = 1896\n",
      "757/466 = 1.62446\n",
      "744-800 = -56\n",
      "534%225 = 84\n",
      "723+229 = 952\n",
      "796+613 = 1409\n",
      "684-488 = 196\n",
      "254+7 = 261\n",
      "675-517 = 158\n",
      "871/965 = 0.90259\n",
      "579/822 = 0.70438\n",
      "710+286 = 996\n",
      "296%521 = 296\n",
      "836*105 = 87780\n",
      "175/769 = 0.22757\n",
      "283%724 = 283\n",
      "113/384 = 0.29427\n",
      "662-463 = 199\n",
      "279*404 = 112716\n",
      "297*904 = 268488\n"
     ]
    }
   ],
   "source": [
    "quick_for_debugg = False\n",
    "n_samples = 100 if quick_for_debugg else int(1e5)\n",
    "\n",
    "X, y = math_expressions_generation(n_samples=n_samples, n_digits=3, invert=True)\n",
    "for X_i, y_i in list(zip(X, y))[:20]:\n",
    "    print(X_i[::-1], \"=\", y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eUb-o6rFycX1"
   },
   "source": [
    "# I - Encoder and decoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w1RRzEkgycX2"
   },
   "source": [
    "- encoder and decoder are both GRU models\n",
    "- encoder and decoder both take an input sequence and output $1$ hidden vector for each step in input sequence\n",
    "- the decoder also outputs $1$ softmax per step in input sequence, that corresponds to the next predicted token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duFVQ66FycX3"
   },
   "source": [
    "In the next cells the example is:\n",
    "- sequence to encode: 94+8\n",
    "- sequence to decode: $102\\text{<EOS>}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCyvaiW_ycX5"
   },
   "source": [
    "**NB: In this TP all tensors have a $\\text{batch_size}$ axis in addition to the traditional $\\text{nb_timesteps, vector_dim}$ axes.**\n",
    "**The batch size axis is there because pytorch GRU (and most other pytorch layers) can process tensors organized in batch, meaning that contain several sequences.**\n",
    "**In the returned tensor, the results for each sequence are given along a batch axis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dow3XIarycX6"
   },
   "source": [
    "**encoder and decoder inputs**\n",
    "- for the encoder, the input sequence is the operation: $94+8$\n",
    "<img src=\"../images/encoder_input.png\" style=\"width: 600px;\" />\n",
    "- for the decoder, if using teacher forcing, the input sequence is the off-set of the sequence to decode: $\\text{<GO>}102$\n",
    "<img src=\"../images/decoder_input_all.png\" style=\"width: 600px;\" />\n",
    "- for the decoder, if **not** using teacher forcing, the input sequence is $1$ timestep long and is either the $\\text{<GO>}$ token or the previous predicted token:\n",
    "<img src=\"../images/decoder_input_one.png\" style=\"width: 600px;\" />\n",
    "for the decoder those $3$ scenarios are one: the input sequence is of shape $(\\text{nb_timesteps, batch_size, input_dim})$, the decoder goes through all timesteps for each sequence, produces $1$ hidden vector and $1$ prediction per timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5DOGgU12ycX7"
   },
   "source": [
    "**no attention vs attention**\n",
    "\n",
    "the attention mechanism is handled (and implemented) at the decoder level\n",
    "\n",
    "**no attention**\n",
    "<img src=\"../images/decoder_no_attention_all.png\" style=\"width: 900px;\" />\n",
    "At each timestep, the hidden vector is used to predict the next token\n",
    "\n",
    "**attention**\n",
    "<img src=\"../images/decoder_attention_all.png\" style=\"width: 900px;\" />\n",
    "The attention mechanism here is of type that is performed over the decoder hidden vectors after they are produced.\n",
    "- For each timestep of the decoder input, similarity between the decoder hidden vector and all the encoder hidden vectors is computed. It allows to determine which token in encoder input to focus on. Here similarity is just a dot product $hdec^T \\cdot henc$ between the vectors.\n",
    "- For each timestep of the decoder input, pass this \"attention weights\" vector to a softmax so the weights sum to $1$.\n",
    "- For each timestep of the decoder input, compute a weighted sum of the encoder hidden vectors. This is the context vector. The fact that it is more or less heavily weighted towards certain encoder hidden vector relates to the tokens the algorithm focuses on.\n",
    "- Use the context vector to predict the next token by performing a matrix product to set at the right dimension and apply a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RGLvf8p9ycX8"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size).to(self.device)\n",
    "\n",
    "    \"\"\"\n",
    "    Implement the encoder forward pass.\n",
    "    Compute henc_ts, a tensor that represent all the encoder hidden vectors\n",
    "    for all timesteps for all sequences\n",
    "    henc_ts is of shape (nb_timesteps, batch_size, hidden_size)\n",
    "    Compute henc_final, the final encoder hidden vector for all sequences. \n",
    "    henc_final is of shape (1, batch_size, hidden_size)\n",
    "    note:\n",
    "        - encoder_input is of shape (nb_timesteps, batch_size, input_size)\n",
    "    hints:\n",
    "        - Use the gru attribute\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, encoder_input, henc_init=None):\n",
    "        if henc_init is None:\n",
    "            henc_init = torch.zeros(\n",
    "                1, encoder_input.size()[1], self.hidden_size, device=self.device\n",
    "            ).to(self.device)\n",
    "        # TODO: (done)\n",
    "        henc_ts, henc_final = self.gru(encoder_input, henc_init)\n",
    "        return henc_ts, henc_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HmxW0RuuycX_"
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, device, attention=False):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(output_size, hidden_size).to(self.device)\n",
    "        self.linear = nn.Linear(hidden_size, output_size).to(self.device)\n",
    "        self.attention = attention\n",
    "\n",
    "    \"\"\"\n",
    "    Implement the decoder forward pass.\n",
    "    Compute hdec_ts, a tensor that represent all the decoder hidden vectors\n",
    "    for all timesteps for all sequences\n",
    "    hdec_ts is of shape (nb_timesteps, batch_size, hidden_size)\n",
    "    Compute h_ts, a tensor that represent all the encoder hidden vectors\n",
    "    for all timesteps for all sequences\n",
    "    Compute hdec_final, the final decoder hidden vector for all sequences.\n",
    "    hdec_final is of shape (1, batch_size, hidden_size)\n",
    "        Hint: Use the gru attribute \n",
    "    Compute output, the tensor that represent all the softmax for all timesteps \n",
    "    for all sequences\n",
    "    output is of shape (nb_timesteps, batch_size, hidden_size)\n",
    "        without attention\n",
    "        with attention\n",
    "            compute first context_vectors, a tensor that represent a weighted sum\n",
    "            of encoder hidden vectors at all timesteps for all sequences. \n",
    "            context_vectors is of shape (nb_timesteps, batch_size, hidden_size)\n",
    "                Hint: it is possible to compute it in fully \"vectorial\" way with \n",
    "                pytorch function but do not hesitate to use loops to iterate over\n",
    "                timesteps etc. if it seems easier\n",
    "    \n",
    "    note:\n",
    "        - for the softmax, use the function torch.nn.functional.log_softmax\n",
    "        - follow the above diagrams\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, decoder_input, hdec_init, henc_ts=None):\n",
    "        # TODO: (done)\n",
    "        hdec_ts, hdec_final = self.gru(decoder_input, hdec_init)\n",
    "        if self.attention:\n",
    "            assert henc_ts is not None\n",
    "            # TODO: (done)\n",
    "            batch_size = hdec_ts.shape[1]\n",
    "            nb_timesteps = hdec_ts.shape[0]\n",
    "            context_vectors = []\n",
    "            for b in range(batch_size):\n",
    "                context = []\n",
    "                for t in range(nb_timesteps):\n",
    "                    # Compute similarity\n",
    "                    sim = hdec_ts[t, b, :].matmul(henc_ts[:, b, :].transpose(0, 1))\n",
    "                    # Apply softmax\n",
    "                    sm_sim = F.log_softmax(sim, dim=-1)\n",
    "                    # Compute context vector\n",
    "                    context.append(torch.sum(sm_sim * henc_ts[:, b, :].transpose(0, 1), 1).unsqueeze(0))\n",
    "                # Concatenate to get context tensor\n",
    "                context_vectors.append(torch.cat(context).unsqueeze(0))\n",
    "            # Concatenate to get context tensor for all batches\n",
    "            context_vectors = torch.cat(context_vectors, 0).permute(1, 0, 2)\n",
    "            \n",
    "            # Compute output\n",
    "            output = F.log_softmax(self.linear(context_vectors), dim=-1)\n",
    "        else:\n",
    "            # TODO: (done)\n",
    "            output = F.log_softmax(self.linear(hdec_ts), dim=-1)\n",
    "        return output, hdec_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sa31afWAycYT"
   },
   "source": [
    "# II - Sequence to sequence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yb5l-ceYycYU"
   },
   "source": [
    "**GO** is the character (\"=\") that marks the beginning of decoding for the decoder GRU<br/>\n",
    "**EOS** is the character (\"\\n\") that marks the end of sequence to decode for the decoder GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXkNyoh_ycYV"
   },
   "source": [
    "**global Seq2seq architecture (teacher forcing scenario)**\n",
    "<img src=\"../images/seq2seq_teacher.png\" style=\"width: 1000px;\" />\n",
    "the teacher forcing mechanism is handled (and implemented) at the seq2seq forward pass level.\n",
    "teacher forcing or no teacher forcing depends on the kind of input passed to the decoder.\n",
    "\n",
    "**teacher forcing**\n",
    "<img src=\"../images/teacher_forcing.png\" style=\"width: 600px;\" />\n",
    "- the decoder input is the sequence of expected decoded tokens at all timesteps.\n",
    "- the decoder input is passed in one go to the decoder. The decoder goes through all timesteps and decodes the whole sequence in one go.\n",
    "- the decoder input is of shape $(\\text{nb_timesteps, batch_size, input_dim})$.\n",
    "\n",
    "**no teacher forcing**\n",
    "<img src=\"../images/no_teacher_forcing.png\" style=\"width: 1000px;\" />\n",
    "- the decoder input is $1$ timestep long and either the $\\text{GO}$ token or the previous decoded token\n",
    "- the decoder inputs are passed iteratively in many stages to the decoder. For each stage, the decoder is given as state the previous returned hidden vector and take as input the previous decoded token. It produces a new hidden vector and decoded token that are returned for the next stage.\n",
    "- the decoder input for each stage is of shape $(\\text{1, batch_size, input_dim})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hNzMLICvycYW"
   },
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, X, y, hidden_size=256, learning_rate=0.01, attention=False):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.GO = \"=\"\n",
    "        self.EOS = \"\\n\"\n",
    "        self.dataset_size = None\n",
    "        self.encoder_char_index = None\n",
    "        self.encoder_index_char = None\n",
    "        self.decoder_char_index = None\n",
    "        self.decoder_index_char = None\n",
    "        self.encoder_vocabulary_size = None\n",
    "        self.decoder_vocabulary_size = None\n",
    "        self.max_encoder_sequence_length = None\n",
    "        self.max_decoder_sequence_length = None\n",
    "        self.encoder_input_tr = None\n",
    "        self.encoder_input_val = None\n",
    "        self.decoder_input_tr = None\n",
    "        self.decoder_input_val = None\n",
    "        self.target_tr = None\n",
    "        self.target_val = None\n",
    "        self._set_data_properties_attributes()\n",
    "        self._construct_data_set()\n",
    "        self.encoder = EncoderRNN(\n",
    "            input_size=self.encoder_vocabulary_size,\n",
    "            hidden_size=hidden_size,\n",
    "            device=self.device,\n",
    "        )\n",
    "        self.decoder = DecoderRNN(\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=self.decoder_vocabulary_size,\n",
    "            attention=attention,\n",
    "            device=self.device,\n",
    "        )\n",
    "        self.parameters = list(self.encoder.parameters()) + list(\n",
    "            self.decoder.parameters()\n",
    "        )\n",
    "        self.optimizer = optim.Adam(self.parameters, lr=learning_rate)\n",
    "        self.criterion = nn.NLLLoss(reduction=\"mean\")\n",
    "        # training attributes\n",
    "        self.total_loss = None\n",
    "        self.total_loss_nb_samples = None\n",
    "\n",
    "    def _set_data_properties_attributes(self):\n",
    "        self.y = list(map(lambda token: self.GO + token + self.EOS, self.y))\n",
    "        self.dataset_size = len(self.X)\n",
    "        encoder_characters = sorted(list(set(\"\".join(self.X))))\n",
    "        decoder_characters = sorted(list(set(\"\".join(self.y))))\n",
    "        decoder_characters.remove(self.EOS)\n",
    "        # set EOS at 0 index so argmax on zero vector falls at EOS\n",
    "        decoder_characters = [self.EOS] + decoder_characters\n",
    "        self.encoder_char_index = dict((c, i) for i, c in enumerate(encoder_characters))\n",
    "        self.encoder_index_char = dict((i, c) for i, c in enumerate(encoder_characters))\n",
    "        self.decoder_char_index = dict((c, i) for i, c in enumerate(decoder_characters))\n",
    "        self.decoder_index_char = dict((i, c) for i, c in enumerate(decoder_characters))\n",
    "        self.encoder_vocabulary_size = len(self.encoder_char_index)\n",
    "        self.decoder_vocabulary_size = len(self.decoder_char_index)\n",
    "        self.max_encoder_sequence_length = max([len(sequence) for sequence in self.X])\n",
    "        self.max_decoder_sequence_length = max([len(sequence) for sequence in self.y])\n",
    "        print(\"Number of samples:\", self.dataset_size)\n",
    "        print(\"Number of unique encoder tokens:\", self.encoder_vocabulary_size)\n",
    "        print(\"Number of unique decoder tokens:\", self.decoder_vocabulary_size)\n",
    "        print(\"Max sequence length for encoding:\", self.max_encoder_sequence_length)\n",
    "        print(\"Max sequence length for decoding:\", self.max_decoder_sequence_length)\n",
    "\n",
    "    def _construct_data_set(self):\n",
    "        encoder_input = torch.zeros(\n",
    "            (\n",
    "                self.max_encoder_sequence_length,\n",
    "                self.dataset_size,\n",
    "                self.encoder_vocabulary_size,\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        decoder_input = torch.zeros(\n",
    "            (\n",
    "                self.max_decoder_sequence_length,\n",
    "                self.dataset_size,\n",
    "                self.decoder_vocabulary_size,\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        target = torch.zeros(\n",
    "            (\n",
    "                self.max_decoder_sequence_length,\n",
    "                self.dataset_size,\n",
    "                self.decoder_vocabulary_size,\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "\n",
    "        for i, (X_i, y_i) in enumerate(zip(self.X, self.y)):\n",
    "            for t, char in enumerate(X_i):\n",
    "                encoder_input[t, i, self.encoder_char_index[char]] = 1.0\n",
    "            for t, char in enumerate(y_i):\n",
    "                decoder_input[t, i, self.decoder_char_index[char]] = 1.0\n",
    "                if t > 0:\n",
    "                    target[t - 1, i, self.decoder_char_index[char]] = 1.0\n",
    "\n",
    "        p_val = 0.25\n",
    "        size_val = int(p_val * self.dataset_size)\n",
    "        idxs = np.arange(self.dataset_size)\n",
    "        np.random.shuffle(idxs)\n",
    "        idxs_tr = idxs[:-size_val]\n",
    "        idxs_val = idxs[-size_val:]\n",
    "        (\n",
    "            self.encoder_input_tr,\n",
    "            self.encoder_input_val,\n",
    "            self.decoder_input_tr,\n",
    "            self.decoder_input_val,\n",
    "            self.target_tr,\n",
    "            self.target_val,\n",
    "        ) = (\n",
    "            encoder_input[:, idxs_tr, :],\n",
    "            encoder_input[:, idxs_val, :],\n",
    "            decoder_input[:, idxs_tr, :],\n",
    "            decoder_input[:, idxs_val, :],\n",
    "            target[:, idxs_tr, :],\n",
    "            target[:, idxs_val, :],\n",
    "        )\n",
    "        self.encoder_input_tr = self.encoder_input_tr.to(self.device)\n",
    "        self.encoder_input_val = self.encoder_input_val.to(self.device)\n",
    "        self.decoder_input_tr = self.decoder_input_tr.to(self.device)\n",
    "        self.decoder_input_val = self.decoder_input_val.to(self.device)\n",
    "        self.target_tr = self.target_tr.to(self.device)\n",
    "        self.target_val = self.target_val.to(self.device)\n",
    "\n",
    "    \"\"\"\n",
    "    Implement the Seq2seq forward pass.\n",
    "    Compute henc_ts, the tensor that represent all the encoder hidden vectors\n",
    "    for all timesteps for all sequences\n",
    "    henc_ts is of shape (nb_encoder_timesteps, batch_size, hidden_size)\n",
    "    Compute henc_final, the final encoder hidden vector for all sequences. \n",
    "    henc_final is of shape (1, batch_size, hidden_size)\n",
    "    Compute pred_softmax_all_ts, the tensor that represents all the softmax\n",
    "    vectors at all timesteps for all sequences.\n",
    "    pred_softmax_all_ts is of shape (nb_decoder_timesteps, batch_size, output_dim)\n",
    "        teacher forcing case\n",
    "            Hint: refer to diagrams notes\n",
    "        no teacher forcing case\n",
    "            Before the loop, initialize decoder_input, the tensor that represents\n",
    "            the first token passed to the decoder for all sequences. \n",
    "            The token is <GO>, the decoder_input is of shape (1, batch_size, output_dim).\n",
    "            It has to be in one-hot encoding representation.\n",
    "            In the loop, compute pred_softmax. The tensor represents the softmax \n",
    "            produced at this timestep, for all sequences. \n",
    "            It is of shape (1, batch_size, output_dim)\n",
    "            In the loop, compute hdec_final. The tensor represents the hidden vector \n",
    "            produced at this timestep, for all sequences. \n",
    "            It is of shape (1, batch_size, hidden_dim)\n",
    "            In the loop, set hdec_init to the right value. \n",
    "            hdec_init is a tensor that represents the state in which the decoder \n",
    "            will start at next stage.\n",
    "            hdec_init is of shape (1, batch_size, hidden_dim)\n",
    "    note:\n",
    "        - in code nb_decoder_timesteps is self.max_decoder_sequence_length\n",
    "        - in code output_dim is self.decoder_vocabulary_size\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(\n",
    "        self, encoder_input, decoder_input=None, teacher_enforce=True, inference=False\n",
    "    ):\n",
    "\n",
    "        batch_size = encoder_input.size()[1]\n",
    "        if inference:\n",
    "            assert (\n",
    "                batch_size == 1\n",
    "            ), \"during inference batch size must be 1: 1 sequence processed\"\n",
    "            if teacher_enforce:\n",
    "                print(\"Warning teacher_enforce will be set to False for inference\")\n",
    "                teacher_enforce = False\n",
    "\n",
    "        # TODO: (done)\n",
    "        henc_ts, henc_final = self.encoder(encoder_input)\n",
    "\n",
    "        if teacher_enforce:\n",
    "            assert decoder_input is not None\n",
    "            # TODO: (done)\n",
    "            pred_softmax_all_ts, hdec_final = self.decoder(decoder_input, henc_final, henc_ts)\n",
    "\n",
    "        elif not teacher_enforce:\n",
    "            pred_softmax_all_ts = []\n",
    "            # TODO: (done)\n",
    "            decoder_input = torch.zeros(1, batch_size, self.decoder_vocabulary_size)\n",
    "            decoder_input[0, :, self.decoder_char_index[self.GO]] = 1.0\n",
    "\n",
    "            decoder_input = decoder_input.to(self.device)\n",
    "            hdec_init = henc_final\n",
    "            # iterate over all decoder stages\n",
    "            for _ in range(self.max_decoder_sequence_length):\n",
    "                # TODO: (done)\n",
    "                pred_softmax, hdec_final = self.decoder(decoder_input, hdec_init, henc_ts)\n",
    "                pred_softmax_all_ts.append(pred_softmax)\n",
    "                # convert softmax predictions to idx\n",
    "                preds_idx = pred_softmax.argmax(dim=2)\n",
    "                # convert idx predictions to one-hot encoding\n",
    "                decoder_input = torch.zeros(1, batch_size, self.decoder_vocabulary_size)\n",
    "                decoder_input = decoder_input.to(self.device)\n",
    "                decoder_input[0, np.arange(batch_size), preds_idx] = 1\n",
    "\n",
    "                # TODO: (done)\n",
    "                hdec_init = hdec_final\n",
    "                if inference:\n",
    "                    pred = preds_idx.squeeze().item()\n",
    "                    if pred == self.decoder_char_index[self.EOS]:\n",
    "                        break\n",
    "            pred_softmax_all_ts = torch.cat(pred_softmax_all_ts)\n",
    "\n",
    "        return pred_softmax_all_ts\n",
    "\n",
    "    def _train_on_batch(\n",
    "        self, encoder_input, target, teacher_forcing, decoder_input=None\n",
    "    ):\n",
    "        self.optimizer.zero_grad()\n",
    "        prediction = self.forward(\n",
    "            encoder_input, decoder_input=decoder_input, teacher_enforce=teacher_forcing\n",
    "        )\n",
    "        target_idx = target.argmax(2)\n",
    "        loss_on_batch = self.criterion(\n",
    "            prediction.reshape(-1, prediction.size()[2]), target_idx.reshape(-1)\n",
    "        )\n",
    "        loss_on_batch.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss_on_batch\n",
    "\n",
    "    def train(self, nb_epoch=10, batch_size=64, teacher_enforce=True):\n",
    "        arr = np.arange(self.encoder_input_tr.size()[1])\n",
    "        np.random.shuffle(arr)\n",
    "        nb_batch = int(self.encoder_input_tr.size()[1] / batch_size)\n",
    "        verbose_every = 5 if nb_batch >= 5 else 1\n",
    "\n",
    "        for epoch in range(nb_epoch):\n",
    "            self._reset_monitor_train_epoch()\n",
    "            if epoch > 0:\n",
    "                print()\n",
    "            for batch_idx in range(nb_batch):\n",
    "                idxs = arr[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "                encoder_input_batch_tr = self.encoder_input_tr[:, idxs, :]\n",
    "                target_batch_tr = self.target_tr[:, idxs, :]\n",
    "                decoder_input_batch_tr = self.decoder_input_tr[:, idxs, :]\n",
    "\n",
    "                batch_loss_tr = self._train_on_batch(\n",
    "                    encoder_input_batch_tr,\n",
    "                    target_batch_tr,\n",
    "                    teacher_forcing=teacher_enforce,\n",
    "                    decoder_input=decoder_input_batch_tr,\n",
    "                )\n",
    "                self._monitor_train_epoch(\n",
    "                    batch_loss=batch_loss_tr,\n",
    "                    batch_size=encoder_input_batch_tr.size()[1],\n",
    "                )\n",
    "\n",
    "                if (batch_idx + 1) % verbose_every == 0:\n",
    "                    self._display_training(\n",
    "                        epoch, nb_epoch, batch_idx, nb_batch, epoch_ended=False\n",
    "                    )\n",
    "\n",
    "            self._monitor_validation(teacher_enforce=teacher_enforce)\n",
    "            self._display_training(\n",
    "                epoch, nb_epoch, batch_idx, nb_batch, epoch_ended=True\n",
    "            )\n",
    "\n",
    "    def _monitor_train_epoch(self, batch_loss, batch_size):\n",
    "        self.total_loss += batch_loss * batch_size\n",
    "        self.total_loss_nb_samples += batch_size\n",
    "\n",
    "    def _reset_monitor_train_epoch(self):\n",
    "        self.total_loss = 0\n",
    "        self.total_loss_nb_samples = 0\n",
    "\n",
    "    def _monitor_validation(self, teacher_enforce):\n",
    "\n",
    "        prediction_val = self(\n",
    "            self.encoder_input_val,\n",
    "            decoder_input=self.decoder_input_val,\n",
    "            teacher_enforce=teacher_enforce,\n",
    "        )\n",
    "        target_val_idx = self.target_val.argmax(2)\n",
    "        self.last_loss_val = self.criterion(\n",
    "            prediction_val.reshape(-1, prediction_val.size()[2]),\n",
    "            target_val_idx.reshape(-1),\n",
    "        )\n",
    "\n",
    "    def _display_training(\n",
    "        self, epoch, nb_epoch, idx_batch, nb_batch, epoch_ended=False\n",
    "    ):\n",
    "        msg = \"Epoch {}/{} {} {}\".format(\n",
    "            epoch + 1,\n",
    "            nb_epoch,\n",
    "            utils.arrow(idx_batch + 1, nb_batch),\n",
    "            \" mean loss: %.5f\" % (self.total_loss.item() / self.total_loss_nb_samples),\n",
    "        )\n",
    "        if epoch_ended:\n",
    "            msg += \" val loss: %.5f\" % self.last_loss_val\n",
    "        print(msg, end=\"\\r\")\n",
    "\n",
    "    def _tensor_to_words(self, output, decoded=True):\n",
    "        dict_index_char = (\n",
    "            self.decoder_index_char if decoded else self.encoder_index_char\n",
    "        )\n",
    "        pred_idx = output.argmax(dim=2)\n",
    "        decoded_words = []\n",
    "        for seq in range(pred_idx.size()[1]):\n",
    "            idxs_chars = pred_idx[:, seq]\n",
    "            decoded_word = \"\".join(dict_index_char[idx.item()] for idx in idxs_chars)\n",
    "            if not decoded:\n",
    "                # correct errors due to zero vectors at the end\n",
    "                accepted_end_chars = set(list(\"0123456789\"))\n",
    "                for i in range(len(decoded_word) - 1, -1, -1):\n",
    "                    if decoded_word[i] in accepted_end_chars:\n",
    "                        decoded_word = decoded_word[: i + 1]\n",
    "                        break\n",
    "            decoded_words.append(decoded_word)\n",
    "        return decoded_words\n",
    "\n",
    "    def evaluate(self, nb=30):\n",
    "        nb = min(nb, self.encoder_input_val.size()[1])\n",
    "        for i in range(nb):\n",
    "            output = self(\n",
    "                self.encoder_input_val[:, i : i + 1, :],\n",
    "                inference=True,\n",
    "                teacher_enforce=False,\n",
    "            )\n",
    "            decoded_word = self._tensor_to_words(output, decoded=True)[0]\n",
    "            operation = self._tensor_to_words(\n",
    "                self.encoder_input_val[:, i : i + 1, :], decoded=False\n",
    "            )[0][::-1]\n",
    "            expected_decoded_word = self._tensor_to_words(\n",
    "                self.target_val[:, i : i + 1, :], decoded=True\n",
    "            )[0]\n",
    "            decoded_word = decoded_word.replace(\"\\n\", \"\")\n",
    "            operation = operation.replace(\"\\n\", \"\")\n",
    "            expected_decoded_word = expected_decoded_word.replace(\"\\n\", \"\")\n",
    "            print(\n",
    "                \"Input sentence: {} Decoded sentence: {} Expected decoded sentence: {}\".format(\n",
    "                    operation, decoded_word, expected_decoded_word\n",
    "                )\n",
    "            )\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zvq469rEycYc"
   },
   "source": [
    "### no attention - teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "HY8zxnUfycYd",
    "outputId": "d7457f43-e9c4-4080-9941-dd048d4c82e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2seq(X, y, hidden_size=128, attention=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "id": "XYnWECJgycYg",
    "outputId": "564d60d3-c3bf-4d48-94ac-21feefc1b11c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 ==================================================>  mean loss: 0.75881 val loss: 0.61876\n",
      "Epoch 2/10 ==================================================>  mean loss: 0.58459 val loss: 0.56294\n",
      "Epoch 3/10 ==================================================>  mean loss: 0.54700 val loss: 0.54049\n",
      "Epoch 4/10 ==================================================>  mean loss: 0.51769 val loss: 0.50774\n",
      "Epoch 5/10 ==================================================>  mean loss: 0.48760 val loss: 0.48260\n",
      "Epoch 6/10 ==================================================>  mean loss: 0.46390 val loss: 0.46086\n",
      "Epoch 7/10 ==================================================>  mean loss: 0.45728 val loss: 0.45261\n",
      "Epoch 8/10 ==================================================>  mean loss: 0.44721 val loss: 0.44893\n",
      "Epoch 9/10 ==================================================>  mean loss: 0.44222 val loss: 0.44616\n"
     ]
    }
   ],
   "source": [
    "seq2seq.train(nb_epoch=10, batch_size=64, teacher_enforce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dqDohjFOycYi",
    "outputId": "32ad4883-22f1-4034-956a-90b5a2ba762f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 935%420 Decoded sentence: 155 Expected decoded sentence: 95========\n",
      "\n",
      "Input sentence: 175+792 Decoded sentence: 967 Expected decoded sentence: 967=======\n",
      "\n",
      "Input sentence: 553-806 Decoded sentence: -283 Expected decoded sentence: -253======\n",
      "\n",
      "Input sentence: 573-173 Decoded sentence: 400 Expected decoded sentence: 400=======\n",
      "\n",
      "Input sentence: 513%727 Decoded sentence: 513 Expected decoded sentence: 513=======\n",
      "\n",
      "Input sentence: 9171-76 Decoded sentence: 135 Expected decoded sentence: 95========\n",
      "\n",
      "Input sentence: 811%789 Decoded sentence: 100 Expected decoded sentence: 22========\n",
      "\n",
      "Input sentence: 534%646 Decoded sentence: 534 Expected decoded sentence: 534=======\n",
      "\n",
      "Input sentence: 515+204 Decoded sentence: 739 Expected decoded sentence: 719=======\n",
      "\n",
      "Input sentence: 214%721 Decoded sentence: 214 Expected decoded sentence: 214=======\n",
      "\n",
      "Input sentence: 332-428 Decoded sentence: -106 Expected decoded sentence: -96=======\n",
      "\n",
      "Input sentence: 805%770 Decoded sentence: 105 Expected decoded sentence: 35========\n",
      "\n",
      "Input sentence: 320/797 Decoded sentence: 0.40777 Expected decoded sentence: 0.40151===\n",
      "\n",
      "Input sentence: 354/674 Decoded sentence: 0.52478 Expected decoded sentence: 0.52522===\n",
      "\n",
      "Input sentence: 617%983 Decoded sentence: 617 Expected decoded sentence: 617=======\n",
      "\n",
      "Input sentence: 651+196 Decoded sentence: 837 Expected decoded sentence: 847=======\n",
      "\n",
      "Input sentence: 667-196 Decoded sentence: 481 Expected decoded sentence: 471=======\n",
      "\n",
      "Input sentence: 479-941 Decoded sentence: -482 Expected decoded sentence: -462======\n",
      "\n",
      "Input sentence: 398/193 Decoded sentence: 2.00000 Expected decoded sentence: 2.06218===\n",
      "\n",
      "Input sentence: 133%453 Decoded sentence: 133 Expected decoded sentence: 133=======\n",
      "\n",
      "Input sentence: 561*871 Decoded sentence: 450861 Expected decoded sentence: 488631====\n",
      "\n",
      "Input sentence: 506+577 Decoded sentence: 1053 Expected decoded sentence: 1083======\n",
      "\n",
      "Input sentence: 983*439 Decoded sentence: 34847 Expected decoded sentence: 36437=====\n",
      "\n",
      "Input sentence: 900+355 Decoded sentence: 1305 Expected decoded sentence: 1255======\n",
      "\n",
      "Input sentence: 230+281 Decoded sentence: 501 Expected decoded sentence: 511=======\n",
      "\n",
      "Input sentence: 477%840 Decoded sentence: 477 Expected decoded sentence: 477=======\n",
      "\n",
      "Input sentence: 713%358 Decoded sentence: 285 Expected decoded sentence: 355=======\n",
      "\n",
      "Input sentence: 848%982 Decoded sentence: 848 Expected decoded sentence: 848=======\n",
      "\n",
      "Input sentence: 616/316 Decoded sentence: 1.73248 Expected decoded sentence: 1.94937===\n",
      "\n",
      "Input sentence: 148*965 Decoded sentence: 137870 Expected decoded sentence: 142820====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBoeF-rjycYl"
   },
   "source": [
    "### no attention - no teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "KvpBcMjPycYl",
    "outputId": "eb22cbce-1aff-4e95-8b3d-c88d83d68a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2seq(X, y, hidden_size=128, attention=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "YGvBSuu2ycYo",
    "outputId": "36a85f3a-e468-478f-96bd-ffe4e08c894f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 ==================================================>  mean loss: 0.78623 val loss: 0.65055\n",
      "Epoch 2/10 ==================================================>  mean loss: 0.61471 val loss: 0.60046\n",
      "Epoch 3/10 ==================================================>  mean loss: 0.58922 val loss: 0.59055\n",
      "Epoch 4/10 ==================================================>  mean loss: 0.57778 val loss: 0.57606\n",
      "Epoch 5/10 ==================================================>  mean loss: 0.55848 val loss: 0.55140\n",
      "Epoch 6/10 ==================================================>  mean loss: 0.54653 val loss: 0.54697\n",
      "Epoch 7/10 ==================================================>  mean loss: 0.53752 val loss: 0.53811\n",
      "Epoch 8/10 ==================================================>  mean loss: 0.52880 val loss: 0.52890\n",
      "Epoch 9/10 ==================================================>  mean loss: 0.54039 val loss: 0.53874\n",
      "Epoch 10/10 ==================================================>  mean loss: 0.51794 val loss: 0.51888\r"
     ]
    }
   ],
   "source": [
    "seq2seq.train(nb_epoch=10, batch_size=64, teacher_enforce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EPZVOX5hycYr",
    "outputId": "4edf9f32-1d66-4c9f-f70e-9a9999d3a381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 487%43 Decoded sentence: 2 Expected decoded sentence: 14\n",
      "\n",
      "Input sentence: 771-97 Decoded sentence: 678 Expected decoded sentence: 674\n",
      "\n",
      "Input sentence: 493*267 Decoded sentence: 116599 Expected decoded sentence: 131631\n",
      "\n",
      "Input sentence: 403+143 Decoded sentence: 506 Expected decoded sentence: 546\n",
      "\n",
      "Input sentence: 286-704 Decoded sentence: -468 Expected decoded sentence: -418\n",
      "\n",
      "Input sentence: 470-652 Decoded sentence: -188 Expected decoded sentence: -182\n",
      "\n",
      "Input sentence: 73-433 Decoded sentence: -300 Expected decoded sentence: -360\n",
      "\n",
      "Input sentence: 129%69 Decoded sentence: 26 Expected decoded sentence: 60\n",
      "\n",
      "Input sentence: 40%594 Decoded sentence: 40 Expected decoded sentence: 40\n",
      "\n",
      "Input sentence: 613-167 Decoded sentence: 460 Expected decoded sentence: 446\n",
      "\n",
      "Input sentence: 841/678 Decoded sentence: 1.26505 Expected decoded sentence: 1.24041\n",
      "\n",
      "Input sentence: 627-122 Decoded sentence: 505 Expected decoded sentence: 505\n",
      "\n",
      "Input sentence: 15%79 Decoded sentence: 15 Expected decoded sentence: 15\n",
      "\n",
      "Input sentence: 871/688 Decoded sentence: 1.26559 Expected decoded sentence: 1.26599\n",
      "\n",
      "Input sentence: 653-950 Decoded sentence: -287 Expected decoded sentence: -297\n",
      "\n",
      "Input sentence: 644+109 Decoded sentence: 705 Expected decoded sentence: 753\n",
      "\n",
      "Input sentence: 735-920 Decoded sentence: -165 Expected decoded sentence: -185\n",
      "\n",
      "Input sentence: 639-570 Decoded sentence: 69 Expected decoded sentence: 69\n",
      "\n",
      "Input sentence: 245%79 Decoded sentence: 66 Expected decoded sentence: 8\n",
      "\n",
      "Input sentence: 481-375 Decoded sentence: 186 Expected decoded sentence: 106\n",
      "\n",
      "Input sentence: 193+493 Decoded sentence: 666 Expected decoded sentence: 686\n",
      "\n",
      "Input sentence: 806/895 Decoded sentence: 0.86665 Expected decoded sentence: 0.90056\n",
      "\n",
      "Input sentence: 90-667 Decoded sentence: -583 Expected decoded sentence: -577\n",
      "\n",
      "Input sentence: 24%71 Decoded sentence: 3 Expected decoded sentence: 24\n",
      "\n",
      "Input sentence: 716%307 Decoded sentence: 15 Expected decoded sentence: 102\n",
      "\n",
      "Input sentence: 39-907 Decoded sentence: -878 Expected decoded sentence: -868\n",
      "\n",
      "Input sentence: 26+670 Decoded sentence: 766 Expected decoded sentence: 696\n",
      "\n",
      "Input sentence: 958+193 Decoded sentence: 1105 Expected decoded sentence: 1151\n",
      "\n",
      "Input sentence: 809*173 Decoded sentence: 126053 Expected decoded sentence: 139957\n",
      "\n",
      "Input sentence: 783-186 Decoded sentence: 507 Expected decoded sentence: 597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BgPFIscGycYt"
   },
   "source": [
    "### attention - teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "VqZk_gEaycYt",
    "outputId": "9511b64d-97b5-474c-8378-8f98081bdc6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn = Seq2seq(X, y, hidden_size=128, attention=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From this try, we ran the notebook on Google Colab because we had vram issues. It ran well on Colab but the printing of the training phases went bad. This is why all the training epochs are not displayed, even though they were all computed before the evaluation part. We did see how the training phase was going before we had the memory issue: the loss was decreasing at each epoch, but slower than the model without attention. We'll give our insight on this in the final questions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "9owX3MZdycY2",
    "outputId": "d2472aca-fc69-491c-a75b-a03023c6318d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn.train(nb_epoch=3, batch_size=64, teacher_enforce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "TFuhDOqVycY4",
    "outputId": "80b9f9d0-c948-468b-c8dc-64b7e6148ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 974*896 Decoded sentence: 882282 Expected decoded sentence: 872704====\n",
      "\n",
      "Input sentence: 998/473 Decoded sentence: 2.05000 Expected decoded sentence: 2.10994===\n",
      "\n",
      "Input sentence: 985/859 Decoded sentence: 1.22222 Expected decoded sentence: 1.14668===\n",
      "\n",
      "Input sentence: 386/451 Decoded sentence: 0.75222 Expected decoded sentence: 0.85588===\n",
      "\n",
      "Input sentence: 9928+20 Decoded sentence: 88 Expected decoded sentence: 48========\n",
      "\n",
      "Input sentence: 110+626 Decoded sentence: 782 Expected decoded sentence: 736=======\n",
      "\n",
      "Input sentence: 419/454 Decoded sentence: 0.85000 Expected decoded sentence: 0.92291===\n",
      "\n",
      "Input sentence: 294/256 Decoded sentence: 0.95000 Expected decoded sentence: 1.14844===\n",
      "\n",
      "Input sentence: 370+151 Decoded sentence: 590 Expected decoded sentence: 521=======\n",
      "\n",
      "Input sentence: 207%880 Decoded sentence: 207 Expected decoded sentence: 207=======\n",
      "\n",
      "Input sentence: 967*494 Decoded sentence: 24448 Expected decoded sentence: 33098=====\n",
      "\n",
      "Input sentence: 310*399 Decoded sentence: 00000 Expected decoded sentence: 123690====\n",
      "\n",
      "Input sentence: 974-515 Decoded sentence: 452 Expected decoded sentence: 459=======\n",
      "\n",
      "Input sentence: 593+924 Decoded sentence: 1505 Expected decoded sentence: 1517======\n",
      "\n",
      "Input sentence: 340-973 Decoded sentence: -505 Expected decoded sentence: -633======\n",
      "\n",
      "Input sentence: 970/809 Decoded sentence: 0.06800 Expected decoded sentence: 0.08653===\n",
      "\n",
      "Input sentence: 952-865 Decoded sentence: 22 Expected decoded sentence: 87========\n",
      "\n",
      "Input sentence: 279+666 Decoded sentence: 1020 Expected decoded sentence: 945=======\n",
      "\n",
      "Input sentence: 311*337 Decoded sentence: 82222 Expected decoded sentence: 104807====\n",
      "\n",
      "Input sentence: 917%566 Decoded sentence: 211 Expected decoded sentence: 351=======\n",
      "\n",
      "Input sentence: 983/487 Decoded sentence: 2.14444 Expected decoded sentence: 2.01848===\n",
      "\n",
      "Input sentence: 925%290 Decoded sentence: 25 Expected decoded sentence: 25========\n",
      "\n",
      "Input sentence: 989-274 Decoded sentence: 666 Expected decoded sentence: 715=======\n",
      "\n",
      "Input sentence: 358/401 Decoded sentence: 0.70000 Expected decoded sentence: 0.89277===\n",
      "\n",
      "Input sentence: 956-596 Decoded sentence: 323 Expected decoded sentence: 360=======\n",
      "\n",
      "Input sentence: 904*183 Decoded sentence: 144444 Expected decoded sentence: 165432====\n",
      "\n",
      "Input sentence: 314/940 Decoded sentence: 0.33200 Expected decoded sentence: 0.33404===\n",
      "\n",
      "Input sentence: 816%810 Decoded sentence: 26 Expected decoded sentence: 6=========\n",
      "\n",
      "Input sentence: 948/926 Decoded sentence: 1.09990 Expected decoded sentence: 1.02376===\n",
      "\n",
      "Input sentence: 334+559 Decoded sentence: 920 Expected decoded sentence: 893=======\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZZO-sKo9ycY6"
   },
   "source": [
    "### attention - no teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "uJ6lR0dcycY7",
    "outputId": "fc5539ac-683b-437b-cc78-319542b97c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn = Seq2seq(X, y, hidden_size=128, attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "Yyl1jca1ycY9",
    "outputId": "222c8eb8-558a-4d88-b80d-d70f63b99ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3 ==================================================>  mean loss: 0.73349 val loss: 0.70802\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn.train(nb_epoch=3, batch_size=64, teacher_enforce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BlRApbrTycY_",
    "outputId": "3e91e497-53f2-4004-a83f-f2a474e452b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 375%378 Decoded sentence: 17 Expected decoded sentence: 375=======\n",
      "\n",
      "Input sentence: 385-731 Decoded sentence: -324 Expected decoded sentence: -346======\n",
      "\n",
      "Input sentence: 837/198 Decoded sentence: 4.35838 Expected decoded sentence: 4.22727===\n",
      "\n",
      "Input sentence: 905*700 Decoded sentence: 500000 Expected decoded sentence: 633500====\n",
      "\n",
      "Input sentence: 692+823 Decoded sentence: 1505 Expected decoded sentence: 1515======\n",
      "\n",
      "Input sentence: 546-782 Decoded sentence: -245 Expected decoded sentence: -236======\n",
      "\n",
      "Input sentence: 354/318 Decoded sentence: 1.28388 Expected decoded sentence: 1.11321===\n",
      "\n",
      "Input sentence: 592-266 Decoded sentence: 333 Expected decoded sentence: 326=======\n",
      "\n",
      "Input sentence: 190*409 Decoded sentence: 62000 Expected decoded sentence: 77710=====\n",
      "\n",
      "Input sentence: 380-680 Decoded sentence: -230 Expected decoded sentence: -300======\n",
      "\n",
      "Input sentence: 244*482 Decoded sentence: 122622 Expected decoded sentence: 117608====\n",
      "\n",
      "Input sentence: 738+826 Decoded sentence: 1580 Expected decoded sentence: 1564======\n",
      "\n",
      "Input sentence: 978%464 Decoded sentence: 78 Expected decoded sentence: 78========\n",
      "\n",
      "Input sentence: 938%935 Decoded sentence: 38 Expected decoded sentence: 38========\n",
      "\n",
      "Input sentence: 316*681 Decoded sentence: 222888 Expected decoded sentence: 215196====\n",
      "\n",
      "Input sentence: 133/416 Decoded sentence: 0.38440 Expected decoded sentence: 0.31971===\n",
      "\n",
      "Input sentence: 188+377 Decoded sentence: 500 Expected decoded sentence: 565=======\n",
      "\n",
      "Input sentence: 604%561 Decoded sentence: 60 Expected decoded sentence: 43========\n",
      "\n",
      "Input sentence: 964*147 Decoded sentence: 148488 Expected decoded sentence: 141708====\n",
      "\n",
      "Input sentence: 841*944 Decoded sentence: 845845 Expected decoded sentence: 793904====\n",
      "\n",
      "Input sentence: 419-554 Decoded sentence: -133 Expected decoded sentence: -135======\n",
      "\n",
      "Input sentence: 226-103 Decoded sentence: 133 Expected decoded sentence: 123=======\n",
      "\n",
      "Input sentence: 358/947 Decoded sentence: 0.33833 Expected decoded sentence: 0.37804===\n",
      "\n",
      "Input sentence: 180-210 Decoded sentence: -30 Expected decoded sentence: -30=======\n",
      "\n",
      "Input sentence: 435*386 Decoded sentence: 150550 Expected decoded sentence: 167910====\n",
      "\n",
      "Input sentence: 621*422 Decoded sentence: 238488 Expected decoded sentence: 262062====\n",
      "\n",
      "Input sentence: 504*658 Decoded sentence: 328820 Expected decoded sentence: 331632====\n",
      "\n",
      "Input sentence: 453/742 Decoded sentence: 0.63833 Expected decoded sentence: 0.61051===\n",
      "\n",
      "Input sentence: 560+260 Decoded sentence: 700 Expected decoded sentence: 820=======\n",
      "\n",
      "Input sentence: 604+509 Decoded sentence: 1105 Expected decoded sentence: 1113======\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4dE7o0jGycZC"
   },
   "source": [
    "###Questions:\n",
    "- 1) Explain the interest in using teacher forcing during training. What is specific about this process?\n",
    "\n",
    "When we don't use teacher forcing, the output of the decoder at a timestep is fed to the decoder's input at the next timestep. However, when the model isn't trained, the computed output is very bad. This means that the model needs to train while being given false inputs. It takes logically a lot more time to converge. With teacher forcing, we give, during training, the right input to the decoder instead of its previous output. With the perfectly right inputs, the model can learn much faster.\n",
    "\n",
    "Another huge avantage of teacher forcing is the fact that we don't need to compute the output at a timestep to start the next one. We just pass the inputs for all timesteps to the GRU model and it computes all outputs and the final hidden. This allows for better parallelization, and thus much faster forward pass.\n",
    "- 2) Describe step by step how the encoder-decoder couple works in this case (~ 5-10 lines)\n",
    "\n",
    "Here, the encoder takes a one-hot encode vector of all characters of the input sequence and computes a final hidden vector that summarizes the input sequence. In our case, we want this summary to somehow correspond to the result of the given calculation, as it is the only thing the decoder will see to produce the output. \n",
    "\n",
    "The decoder then takes this hidden vector and tries to output a sequence of characters that answers well the calculation of the input sequence. To do so, it uses the GRU unit at each timestep to compute a hidden vector. By feeding this vector to a Dense layer (matrix of parameters) and use a softmax operation on the result, we obtain a vector the size of our dictionary that contains the probability of each character. By taking the highest of these and zero the others, we obtain a one-hot encoded vector that corresponds to the character to print.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YalBZUVUycZC"
   },
   "source": [
    "###Questions:\n",
    "- 1) Describe how the attention mechanism works in the seq2seq setting (~ 5-10 lines)\n",
    "\n",
    "The attention occurs at the decoder level. For each timesteps, we assign a weight to each of the encoder's hidden outputs by computing their similarity with the decoder's hidden output. This allows us to look at the input sequence during the decoding part, while choosing the right timesteps to focus on. \n",
    "- 2) Compare the perfomances of your model at inference time with and without attention mechanism. Do you see noticeable differences? Why?\n",
    "\n",
    "The models with attention performs worse than the ones that don't use it. The training is slower (the loss decreases slower) and the results at inference time are way worse. We think this is due to the fact that all characters in the input sequence have an impact on all characters of the output sequence. The attention mechanism then looses its interest, adding unnecessary calculation. This makes the training phase less efficient, while taking more time to compute due to our poor implementation of the attention part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "deep_learning_NLP_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
