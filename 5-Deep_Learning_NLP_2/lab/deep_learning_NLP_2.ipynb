{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "sys.path.append(\".\")\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an introduction to basic sequence-to-sequence learning using a Long short term memory (LSTM) module.\n",
    "Given a string of characters representing a math problem \"3141+42\" we would like to generate a string of characters representing the correct solution: \"3183\". Our network will learn how to do basic mathematical operations.\n",
    "The important part is that we will not first use our human intelligence to break the string up into integers and a mathematical operator. We want the computer to figure all that out by itself.\n",
    "Each math problem is an input sequence: a list of {0,...,9} integers and math operation symbols\n",
    "The result of the operation (\"$3141+42$\" $\\rightarrow$ \"$3183$\"</span>) is the sequence to decode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**math_operators** is the set of $5$ operations we are going to use to build are input sequences.<br/>\n",
    "The math_expressions_generation function uses them to generate a large set of examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def math_expressions_generation(n_samples=1000, n_digits=3, invert=True):\n",
    "    X, Y = [], []\n",
    "    math_operators = {\n",
    "        \"+\": operator.add,\n",
    "        \"-\": operator.sub,\n",
    "        \"*\": operator.mul,\n",
    "        \"/\": operator.truediv,\n",
    "        \"%\": operator.mod,\n",
    "    }\n",
    "    for i in range(n_samples):\n",
    "        a, b = np.random.randint(1, 10 ** n_digits, size=2)\n",
    "        op = np.random.choice(list(math_operators.keys()))\n",
    "        res = math_operators[op](a, b)\n",
    "        x = \"\".join([str(elem) for elem in (a, op, b)])\n",
    "        if invert is True:\n",
    "            x = x[::-1]\n",
    "        y = \"{:.5f}\".format(res) if isinstance(res, float) else str(res)\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/339 = 0.88496\n",
      "811+108 = 919\n",
      "555%897 = 555\n",
      "769%828 = 769\n",
      "508/410 = 1.23902\n",
      "804/198 = 4.06061\n",
      "477%99 = 81\n",
      "367%170 = 27\n",
      "494%728 = 494\n",
      "480%129 = 93\n",
      "196%445 = 196\n",
      "297*111 = 32967\n",
      "656/915 = 0.71694\n",
      "580-169 = 411\n",
      "174+61 = 235\n",
      "866-405 = 461\n",
      "180%487 = 180\n",
      "970/76 = 12.76316\n",
      "582/336 = 1.73214\n",
      "541*922 = 498802\n"
     ]
    }
   ],
   "source": [
    "quick_for_debugg = False\n",
    "n_samples = 100 if quick_for_debugg else int(1e5)\n",
    "\n",
    "X, y = math_expressions_generation(n_samples=n_samples, n_digits=3, invert=True)\n",
    "for X_i, y_i in list(zip(X, y))[:20]:\n",
    "    print(X_i[::-1], \"=\", y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Encoder and decoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- encoder and decoder are both GRU models\n",
    "- encoder and decoder both take an input sequence and output $1$ hidden vector for each step in input sequence\n",
    "- the decoder also outputs $1$ softmax per step in input sequence, that corresponds to the next predicted token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cells the example is:\n",
    "- sequence to encode: 94+8\n",
    "- sequence to decode: $102\\text{<EOS>}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB: In this TP all tensors have a $\\text{batch_size}$ axis in addition to the traditional $\\text{nb_timesteps, vector_dim}$ axes.**\n",
    "**The batch size axis is there because pytorch GRU (and most other pytorch layers) can process tensors organized in batch, meaning that contain several sequences.**\n",
    "**In the returned tensor, the results for each sequence are given along a batch axis.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**encoder and decoder inputs**\n",
    "- for the encoder, the input sequence is the operation: $94+8$\n",
    "<img src=\"../images/encoder_input.png\" style=\"width: 600px;\" />\n",
    "- for the decoder, if using teacher forcing, the input sequence is the off-set of the sequence to decode: $\\text{<GO>}102$\n",
    "<img src=\"../images/decoder_input_all.png\" style=\"width: 600px;\" />\n",
    "- for the decoder, if **not** using teacher forcing, the input sequence is $1$ timestep long and is either the $\\text{<GO>}$ token or the previous predicted token:\n",
    "<img src=\"../images/decoder_input_one.png\" style=\"width: 600px;\" />\n",
    "for the decoder those $3$ scenarios are one: the input sequence is of shape $(\\text{nb_timesteps, batch_size, input_dim})$, the decoder goes through all timesteps for each sequence, produces $1$ hidden vector and $1$ prediction per timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no attention vs attention**\n",
    "\n",
    "the attention mechanism is handled (and implemented) at the decoder level\n",
    "\n",
    "**no attention**\n",
    "<img src=\"../images/decoder_no_attention_all.png\" style=\"width: 900px;\" />\n",
    "At each timestep, the hidden vector is used to predict the next token\n",
    "\n",
    "**attention**\n",
    "<img src=\"../images/decoder_attention_all.png\" style=\"width: 900px;\" />\n",
    "The attention mechanism here is of type that is performed over the decoder hidden vectors after they are produced.\n",
    "- For each timestep of the decoder input, similarity between the decoder hidden vector and all the encoder hidden vectors is computed. It allows to determine which token in encoder input to focus on. Here similarity is just a dot product $hdec^T \\cdot henc$ between the vectors.\n",
    "- For each timestep of the decoder input, pass this \"attention weights\" vector to a softmax so the weights sum to $1$.\n",
    "- For each timestep of the decoder input, compute a weighted sum of the encoder hidden vectors. This is the context vector. The fact that it is more or less heavily weighted towards certain encoder hidden vector relates to the tokens the algorithm focuses on.\n",
    "- Use the context vector to predict the next token by performing a matrix product to set at the right dimension and apply a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, device):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size).to(self.device)\n",
    "\n",
    "    \"\"\"\n",
    "    Implement the encoder forward pass.\n",
    "    Compute henc_ts, a tensor that represent all the encoder hidden vectors\n",
    "    for all timesteps for all sequences\n",
    "    henc_ts is of shape (nb_timesteps, batch_size, hidden_size)\n",
    "    Compute henc_final, the final encoder hidden vector for all sequences. \n",
    "    henc_final is of shape (1, batch_size, hidden_size)\n",
    "    note:\n",
    "        - encoder_input is of shape (nb_timesteps, batch_size, input_size)\n",
    "    hints:\n",
    "        - Use the gru attribute\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, encoder_input, henc_init=None):\n",
    "        if henc_init is None:\n",
    "            henc_init = torch.zeros(\n",
    "                1, encoder_input.size()[1], self.hidden_size, device=self.device\n",
    "            ).to(self.device)\n",
    "        # TODO: (done)\n",
    "        henc_ts, henc_final = self.gru(encoder_input, henc_init)\n",
    "        return henc_ts, henc_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, device, attention=False):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(output_size, hidden_size).to(self.device)\n",
    "        self.linear = nn.Linear(hidden_size, output_size).to(self.device)\n",
    "        self.attention = attention\n",
    "\n",
    "    \"\"\"\n",
    "    Implement the decoder forward pass.\n",
    "    Compute hdec_ts, a tensor that represent all the decoder hidden vectors\n",
    "    for all timesteps for all sequences\n",
    "    hdec_ts is of shape (nb_timesteps, batch_size, hidden_size)\n",
    "    Compute h_ts, a tensor that represent all the encoder hidden vectors\n",
    "    for all timesteps for all sequences\n",
    "    Compute hdec_final, the final decoder hidden vector for all sequences.\n",
    "    hdec_final is of shape (1, batch_size, hidden_size)\n",
    "        Hint: Use the gru attribute \n",
    "    Compute output, the tensor that represent all the softmax for all timesteps \n",
    "    for all sequences\n",
    "    output is of shape (nb_timesteps, batch_size, hidden_size)\n",
    "        without attention\n",
    "        with attention\n",
    "            compute first context_vectors, a tensor that represent a weighted sum\n",
    "            of encoder hidden vectors at all timesteps for all sequences. \n",
    "            context_vectors is of shape (nb_timesteps, batch_size, hidden_size)\n",
    "                Hint: it is possible to compute it in fully \"vectorial\" way with \n",
    "                pytorch function but do not hesitate to use loops to iterate over\n",
    "                timesteps etc. if it seems easier\n",
    "    \n",
    "    note:\n",
    "        - for the softmax, use the function torch.nn.functional.log_softmax\n",
    "        - follow the above diagrams\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, decoder_input, hdec_init, henc_ts=None):\n",
    "        # TODO: (done)\n",
    "        hdec_ts, hdec_final = self.gru(decoder_input, hdec_init)\n",
    "        if self.attention:\n",
    "            assert henc_ts is not None\n",
    "            # TODO: (done)\n",
    "            batch_size = hdec_ts.shape[1]\n",
    "            nb_timesteps = hdec_ts.shape[0]\n",
    "            context_vectors = []\n",
    "            for b in range(batch_size):\n",
    "                context = []\n",
    "                for t in range(nb_timesteps):\n",
    "                    # Compute similarity\n",
    "                    sim = hdec_ts[t, b, :].matmul(henc_ts[:, b, :].transpose(0, 1))\n",
    "                    # Apply softmax\n",
    "                    sm_sim = F.log_softmax(sim, dim=-1)\n",
    "                    # Compute context vector\n",
    "                    context.append(torch.sum(sm_sim * henc_ts[:, b, :].transpose(0, 1), 1).unsqueeze(0))\n",
    "                # Concatenate to get context tensor\n",
    "                context_vectors.append(torch.cat(context).unsqueeze(0))\n",
    "            # Concatenate to get context tensor for all batches\n",
    "            context_vectors = torch.cat(context_vectors, 0).permute(1, 0, 2)\n",
    "            \n",
    "            # Compute output\n",
    "            output = F.log_softmax(self.linear(context_vectors), dim=-1)\n",
    "        else:\n",
    "            # TODO: (done)\n",
    "            output = F.log_softmax(self.linear(hdec_ts), dim=-1)\n",
    "        return output, hdec_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2500, 0.5000, 0.7500],\n",
       "        [0.0000, 0.2500, 0.5000, 0.7500],\n",
       "        [0.0000, 0.2500, 0.5000, 0.7500],\n",
       "        [0.0000, 0.2500, 0.5000, 0.7500],\n",
       "        [0.0000, 0.2500, 0.5000, 0.7500],\n",
       "        [0.0000, 0.2500, 0.5000, 0.7500],\n",
       "        [0.0000, 0.2500, 0.5000, 0.7500],\n",
       "        [0.0000, 0.2500, 0.5000, 0.7500],\n",
       "        [0.0000, 0.2500, 0.5000, 0.7500],\n",
       "        [0.0000, 0.2500, 0.5000, 0.7500]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.ones(4, 10)\n",
    "d = torch.FloatTensor([0, 0.25, 0.5, 0.75])\n",
    "d*c.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.8000, -1.5500, -1.3000, -1.0500]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([[[0, 0.25, 0.5, 0.75]]])\n",
    "t = F.log_softmax(t, dim=-1)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(10).unsqueeze(0)\n",
    "b = torch.ones(10).unsqueeze(0)\n",
    "print(a.shape)\n",
    "torch.cat([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.zeros(5, 10).unsqueeze(0)\n",
    "b = torch.ones(5, 10).unsqueeze(0)\n",
    "torch.cat([a, b], 0).permute(1, 0, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "c:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:61: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863]],\n",
       " \n",
       "         [[-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863]],\n",
       " \n",
       "         [[-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863]],\n",
       " \n",
       "         [[-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863],\n",
       "          [-1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863, -1.3863,\n",
       "           -1.3863, -1.3863]]], device='cuda:0', grad_fn=<LogSoftmaxBackward>),\n",
       " tensor([[[-0.0158,  0.0636, -0.0744,  0.0698,  0.0025, -0.1108,  0.0045,\n",
       "            0.0224, -0.0511, -0.0003, -0.0891, -0.1099, -0.0780,  0.0567,\n",
       "            0.0323, -0.0177,  0.0917,  0.0567,  0.0311,  0.0538,  0.0844,\n",
       "            0.0933,  0.0818, -0.0621,  0.0500,  0.0458, -0.0419, -0.0580,\n",
       "           -0.0249, -0.0491,  0.0769, -0.0317, -0.0386, -0.0378, -0.0025,\n",
       "            0.0298, -0.1568,  0.0023,  0.0733,  0.0462, -0.0440, -0.0153,\n",
       "           -0.0860,  0.0325,  0.0054,  0.0728,  0.0816, -0.0601, -0.0826,\n",
       "            0.0234,  0.0502,  0.0502,  0.0474,  0.0601, -0.0212, -0.0326,\n",
       "            0.0948, -0.0832, -0.0123,  0.0579, -0.0955,  0.0114,  0.0464,\n",
       "            0.0532,  0.1009,  0.0736, -0.0075, -0.0631, -0.0827, -0.0708,\n",
       "            0.0480,  0.0648,  0.0166,  0.0709,  0.0905, -0.0794,  0.0222,\n",
       "           -0.0390, -0.0402, -0.1037, -0.0040,  0.0313,  0.0476, -0.0086,\n",
       "            0.0480, -0.0538, -0.0248,  0.0927,  0.0731, -0.0132, -0.0688,\n",
       "            0.1181, -0.0342, -0.1107, -0.0829,  0.0106,  0.0007, -0.0950,\n",
       "            0.0107,  0.0381],\n",
       "          [-0.0158,  0.0636, -0.0744,  0.0698,  0.0025, -0.1108,  0.0045,\n",
       "            0.0224, -0.0511, -0.0003, -0.0891, -0.1099, -0.0780,  0.0567,\n",
       "            0.0323, -0.0177,  0.0917,  0.0567,  0.0311,  0.0538,  0.0844,\n",
       "            0.0933,  0.0818, -0.0621,  0.0500,  0.0458, -0.0419, -0.0580,\n",
       "           -0.0249, -0.0491,  0.0769, -0.0317, -0.0386, -0.0378, -0.0025,\n",
       "            0.0298, -0.1568,  0.0023,  0.0733,  0.0462, -0.0440, -0.0153,\n",
       "           -0.0860,  0.0325,  0.0054,  0.0728,  0.0816, -0.0601, -0.0826,\n",
       "            0.0234,  0.0502,  0.0502,  0.0474,  0.0601, -0.0212, -0.0326,\n",
       "            0.0948, -0.0832, -0.0123,  0.0579, -0.0955,  0.0114,  0.0464,\n",
       "            0.0532,  0.1009,  0.0736, -0.0075, -0.0631, -0.0827, -0.0708,\n",
       "            0.0480,  0.0648,  0.0166,  0.0709,  0.0905, -0.0794,  0.0222,\n",
       "           -0.0390, -0.0402, -0.1037, -0.0040,  0.0313,  0.0476, -0.0086,\n",
       "            0.0480, -0.0538, -0.0248,  0.0927,  0.0731, -0.0132, -0.0688,\n",
       "            0.1181, -0.0342, -0.1107, -0.0829,  0.0106,  0.0007, -0.0950,\n",
       "            0.0107,  0.0381],\n",
       "          [-0.0158,  0.0636, -0.0744,  0.0698,  0.0025, -0.1108,  0.0045,\n",
       "            0.0224, -0.0511, -0.0003, -0.0891, -0.1099, -0.0780,  0.0567,\n",
       "            0.0323, -0.0177,  0.0917,  0.0567,  0.0311,  0.0538,  0.0844,\n",
       "            0.0933,  0.0818, -0.0621,  0.0500,  0.0458, -0.0419, -0.0580,\n",
       "           -0.0249, -0.0491,  0.0769, -0.0317, -0.0386, -0.0378, -0.0025,\n",
       "            0.0298, -0.1568,  0.0023,  0.0733,  0.0462, -0.0440, -0.0153,\n",
       "           -0.0860,  0.0325,  0.0054,  0.0728,  0.0816, -0.0601, -0.0826,\n",
       "            0.0234,  0.0502,  0.0502,  0.0474,  0.0601, -0.0212, -0.0326,\n",
       "            0.0948, -0.0832, -0.0123,  0.0579, -0.0955,  0.0114,  0.0464,\n",
       "            0.0532,  0.1009,  0.0736, -0.0075, -0.0631, -0.0827, -0.0708,\n",
       "            0.0480,  0.0648,  0.0166,  0.0709,  0.0905, -0.0794,  0.0222,\n",
       "           -0.0390, -0.0402, -0.1037, -0.0040,  0.0313,  0.0476, -0.0086,\n",
       "            0.0480, -0.0538, -0.0248,  0.0927,  0.0731, -0.0132, -0.0688,\n",
       "            0.1181, -0.0342, -0.1107, -0.0829,  0.0106,  0.0007, -0.0950,\n",
       "            0.0107,  0.0381],\n",
       "          [-0.0158,  0.0636, -0.0744,  0.0698,  0.0025, -0.1108,  0.0045,\n",
       "            0.0224, -0.0511, -0.0003, -0.0891, -0.1099, -0.0780,  0.0567,\n",
       "            0.0323, -0.0177,  0.0917,  0.0567,  0.0311,  0.0538,  0.0844,\n",
       "            0.0933,  0.0818, -0.0621,  0.0500,  0.0458, -0.0419, -0.0580,\n",
       "           -0.0249, -0.0491,  0.0769, -0.0317, -0.0386, -0.0378, -0.0025,\n",
       "            0.0298, -0.1568,  0.0023,  0.0733,  0.0462, -0.0440, -0.0153,\n",
       "           -0.0860,  0.0325,  0.0054,  0.0728,  0.0816, -0.0601, -0.0826,\n",
       "            0.0234,  0.0502,  0.0502,  0.0474,  0.0601, -0.0212, -0.0326,\n",
       "            0.0948, -0.0832, -0.0123,  0.0579, -0.0955,  0.0114,  0.0464,\n",
       "            0.0532,  0.1009,  0.0736, -0.0075, -0.0631, -0.0827, -0.0708,\n",
       "            0.0480,  0.0648,  0.0166,  0.0709,  0.0905, -0.0794,  0.0222,\n",
       "           -0.0390, -0.0402, -0.1037, -0.0040,  0.0313,  0.0476, -0.0086,\n",
       "            0.0480, -0.0538, -0.0248,  0.0927,  0.0731, -0.0132, -0.0688,\n",
       "            0.1181, -0.0342, -0.1107, -0.0829,  0.0106,  0.0007, -0.0950,\n",
       "            0.0107,  0.0381],\n",
       "          [-0.0158,  0.0636, -0.0744,  0.0698,  0.0025, -0.1108,  0.0045,\n",
       "            0.0224, -0.0511, -0.0003, -0.0891, -0.1099, -0.0780,  0.0567,\n",
       "            0.0323, -0.0177,  0.0917,  0.0567,  0.0311,  0.0538,  0.0844,\n",
       "            0.0933,  0.0818, -0.0621,  0.0500,  0.0458, -0.0419, -0.0580,\n",
       "           -0.0249, -0.0491,  0.0769, -0.0317, -0.0386, -0.0378, -0.0025,\n",
       "            0.0298, -0.1568,  0.0023,  0.0733,  0.0462, -0.0440, -0.0153,\n",
       "           -0.0860,  0.0325,  0.0054,  0.0728,  0.0816, -0.0601, -0.0826,\n",
       "            0.0234,  0.0502,  0.0502,  0.0474,  0.0601, -0.0212, -0.0326,\n",
       "            0.0948, -0.0832, -0.0123,  0.0579, -0.0955,  0.0114,  0.0464,\n",
       "            0.0532,  0.1009,  0.0736, -0.0075, -0.0631, -0.0827, -0.0708,\n",
       "            0.0480,  0.0648,  0.0166,  0.0709,  0.0905, -0.0794,  0.0222,\n",
       "           -0.0390, -0.0402, -0.1037, -0.0040,  0.0313,  0.0476, -0.0086,\n",
       "            0.0480, -0.0538, -0.0248,  0.0927,  0.0731, -0.0132, -0.0688,\n",
       "            0.1181, -0.0342, -0.1107, -0.0829,  0.0106,  0.0007, -0.0950,\n",
       "            0.0107,  0.0381]]], device='cuda:0', grad_fn=<CudnnRnnBackward>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev = torch.device(\"cuda:0\")\n",
    "d = DecoderRNN(100, 30, dev, True)\n",
    "\n",
    "d.forward(torch.zeros(4, 5, 30).to(dev), torch.zeros(1, 5, 100).to(dev), torch.zeros(4, 5, 100).to(dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II - Sequence to sequence model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GO** is the character (\"=\") that marks the beginning of decoding for the decoder GRU<br/>\n",
    "**EOS** is the character (\"\\n\") that marks the end of sequence to decode for the decoder GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**global Seq2seq architecture (teacher forcing scenario)**\n",
    "<img src=\"../images/seq2seq_teacher.png\" style=\"width: 1000px;\" />\n",
    "the teacher forcing mechanism is handled (and implemented) at the seq2seq forward pass level.\n",
    "teacher forcing or no teacher forcing depends on the kind of input passed to the decoder.\n",
    "\n",
    "**teacher forcing**\n",
    "<img src=\"../images/teacher_forcing.png\" style=\"width: 600px;\" />\n",
    "- the decoder input is the sequence of expected decoded tokens at all timesteps.\n",
    "- the decoder input is passed in one go to the decoder. The decoder goes through all timesteps and decodes the whole sequence in one go.\n",
    "- the decoder input is of shape $(\\text{nb_timesteps, batch_size, input_dim})$.\n",
    "\n",
    "**no teacher forcing**\n",
    "<img src=\"../images/no_teacher_forcing.png\" style=\"width: 1000px;\" />\n",
    "- the decoder input is $1$ timestep long and either the $\\text{GO}$ token or the previous decoded token\n",
    "- the decoder inputs are passed iteratively in many stages to the decoder. For each stage, the decoder is given as state the previous returned hidden vector and take as input the previous decoded token. It produces a new hidden vector and decoded token that are returned for the next stage.\n",
    "- the decoder input for each stage is of shape $(\\text{1, batch_size, input_dim})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, X, y, hidden_size=256, learning_rate=0.01, attention=False):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.GO = \"=\"\n",
    "        self.EOS = \"\\n\"\n",
    "        self.dataset_size = None\n",
    "        self.encoder_char_index = None\n",
    "        self.encoder_index_char = None\n",
    "        self.decoder_char_index = None\n",
    "        self.decoder_index_char = None\n",
    "        self.encoder_vocabulary_size = None\n",
    "        self.decoder_vocabulary_size = None\n",
    "        self.max_encoder_sequence_length = None\n",
    "        self.max_decoder_sequence_length = None\n",
    "        self.encoder_input_tr = None\n",
    "        self.encoder_input_val = None\n",
    "        self.decoder_input_tr = None\n",
    "        self.decoder_input_val = None\n",
    "        self.target_tr = None\n",
    "        self.target_val = None\n",
    "        self._set_data_properties_attributes()\n",
    "        self._construct_data_set()\n",
    "        self.encoder = EncoderRNN(\n",
    "            input_size=self.encoder_vocabulary_size,\n",
    "            hidden_size=hidden_size,\n",
    "            device=self.device,\n",
    "        )\n",
    "        self.decoder = DecoderRNN(\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=self.decoder_vocabulary_size,\n",
    "            attention=attention,\n",
    "            device=self.device,\n",
    "        )\n",
    "        self.parameters = list(self.encoder.parameters()) + list(\n",
    "            self.decoder.parameters()\n",
    "        )\n",
    "        self.optimizer = optim.Adam(self.parameters, lr=learning_rate)\n",
    "        self.criterion = nn.NLLLoss(reduction=\"mean\")\n",
    "        # training attributes\n",
    "        self.total_loss = None\n",
    "        self.total_loss_nb_samples = None\n",
    "\n",
    "    def _set_data_properties_attributes(self):\n",
    "        self.y = list(map(lambda token: self.GO + token + self.EOS, self.y))\n",
    "        self.dataset_size = len(self.X)\n",
    "        encoder_characters = sorted(list(set(\"\".join(self.X))))\n",
    "        decoder_characters = sorted(list(set(\"\".join(self.y))))\n",
    "        decoder_characters.remove(self.EOS)\n",
    "        # set EOS at 0 index so argmax on zero vector falls at EOS\n",
    "        decoder_characters = [self.EOS] + decoder_characters\n",
    "        self.encoder_char_index = dict((c, i) for i, c in enumerate(encoder_characters))\n",
    "        self.encoder_index_char = dict((i, c) for i, c in enumerate(encoder_characters))\n",
    "        self.decoder_char_index = dict((c, i) for i, c in enumerate(decoder_characters))\n",
    "        self.decoder_index_char = dict((i, c) for i, c in enumerate(decoder_characters))\n",
    "        self.encoder_vocabulary_size = len(self.encoder_char_index)\n",
    "        self.decoder_vocabulary_size = len(self.decoder_char_index)\n",
    "        self.max_encoder_sequence_length = max([len(sequence) for sequence in self.X])\n",
    "        self.max_decoder_sequence_length = max([len(sequence) for sequence in self.y])\n",
    "        print(\"Number of samples:\", self.dataset_size)\n",
    "        print(\"Number of unique encoder tokens:\", self.encoder_vocabulary_size)\n",
    "        print(\"Number of unique decoder tokens:\", self.decoder_vocabulary_size)\n",
    "        print(\"Max sequence length for encoding:\", self.max_encoder_sequence_length)\n",
    "        print(\"Max sequence length for decoding:\", self.max_decoder_sequence_length)\n",
    "\n",
    "    def _construct_data_set(self):\n",
    "        encoder_input = torch.zeros(\n",
    "            (\n",
    "                self.max_encoder_sequence_length,\n",
    "                self.dataset_size,\n",
    "                self.encoder_vocabulary_size,\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        decoder_input = torch.zeros(\n",
    "            (\n",
    "                self.max_decoder_sequence_length,\n",
    "                self.dataset_size,\n",
    "                self.decoder_vocabulary_size,\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        target = torch.zeros(\n",
    "            (\n",
    "                self.max_decoder_sequence_length,\n",
    "                self.dataset_size,\n",
    "                self.decoder_vocabulary_size,\n",
    "            ),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "\n",
    "        for i, (X_i, y_i) in enumerate(zip(self.X, self.y)):\n",
    "            for t, char in enumerate(X_i):\n",
    "                encoder_input[t, i, self.encoder_char_index[char]] = 1.0\n",
    "            for t, char in enumerate(y_i):\n",
    "                decoder_input[t, i, self.decoder_char_index[char]] = 1.0\n",
    "                if t > 0:\n",
    "                    target[t - 1, i, self.decoder_char_index[char]] = 1.0\n",
    "\n",
    "        p_val = 0.25\n",
    "        size_val = int(p_val * self.dataset_size)\n",
    "        idxs = np.arange(self.dataset_size)\n",
    "        np.random.shuffle(idxs)\n",
    "        idxs_tr = idxs[:-size_val]\n",
    "        idxs_val = idxs[-size_val:]\n",
    "        (\n",
    "            self.encoder_input_tr,\n",
    "            self.encoder_input_val,\n",
    "            self.decoder_input_tr,\n",
    "            self.decoder_input_val,\n",
    "            self.target_tr,\n",
    "            self.target_val,\n",
    "        ) = (\n",
    "            encoder_input[:, idxs_tr, :],\n",
    "            encoder_input[:, idxs_val, :],\n",
    "            decoder_input[:, idxs_tr, :],\n",
    "            decoder_input[:, idxs_val, :],\n",
    "            target[:, idxs_tr, :],\n",
    "            target[:, idxs_val, :],\n",
    "        )\n",
    "        self.encoder_input_tr = self.encoder_input_tr.to(self.device)\n",
    "        self.encoder_input_val = self.encoder_input_val.to(self.device)\n",
    "        self.decoder_input_tr = self.decoder_input_tr.to(self.device)\n",
    "        self.decoder_input_val = self.decoder_input_val.to(self.device)\n",
    "        self.target_tr = self.target_tr.to(self.device)\n",
    "        self.target_val = self.target_val.to(self.device)\n",
    "\n",
    "    \"\"\"\n",
    "    Implement the Seq2seq forward pass.\n",
    "    Compute henc_ts, the tensor that represent all the encoder hidden vectors\n",
    "    for all timesteps for all sequences\n",
    "    henc_ts is of shape (nb_encoder_timesteps, batch_size, hidden_size)\n",
    "    Compute henc_final, the final encoder hidden vector for all sequences. \n",
    "    henc_final is of shape (1, batch_size, hidden_size)\n",
    "    Compute pred_softmax_all_ts, the tensor that represents all the softmax\n",
    "    vectors at all timesteps for all sequences.\n",
    "    pred_softmax_all_ts is of shape (nb_decoder_timesteps, batch_size, output_dim)\n",
    "        teacher forcing case\n",
    "            Hint: refer to diagrams notes\n",
    "        no teacher forcing case\n",
    "            Before the loop, initialize decoder_input, the tensor that represents\n",
    "            the first token passed to the decoder for all sequences. \n",
    "            The token is <GO>, the decoder_input is of shape (1, batch_size, output_dim).\n",
    "            It has to be in one-hot encoding representation.\n",
    "            In the loop, compute pred_softmax. The tensor represents the softmax \n",
    "            produced at this timestep, for all sequences. \n",
    "            It is of shape (1, batch_size, output_dim)\n",
    "            In the loop, compute hdec_final. The tensor represents the hidden vector \n",
    "            produced at this timestep, for all sequences. \n",
    "            It is of shape (1, batch_size, hidden_dim)\n",
    "            In the loop, set hdec_init to the right value. \n",
    "            hdec_init is a tensor that represents the state in which the decoder \n",
    "            will start at next stage.\n",
    "            hdec_init is of shape (1, batch_size, hidden_dim)\n",
    "    note:\n",
    "        - in code nb_decoder_timesteps is self.max_decoder_sequence_length\n",
    "        - in code output_dim is self.decoder_vocabulary_size\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(\n",
    "        self, encoder_input, decoder_input=None, teacher_enforce=True, inference=False\n",
    "    ):\n",
    "\n",
    "        batch_size = encoder_input.size()[1]\n",
    "        if inference:\n",
    "            assert (\n",
    "                batch_size == 1\n",
    "            ), \"during inference batch size must be 1: 1 sequence processed\"\n",
    "            if teacher_enforce:\n",
    "                print(\"Warning teacher_enforce will be set to False for inference\")\n",
    "                teacher_enforce = False\n",
    "\n",
    "        # TODO: (done)\n",
    "        henc_ts, henc_final = self.encoder(encoder_input)\n",
    "\n",
    "        if teacher_enforce:\n",
    "            assert decoder_input is not None\n",
    "            # TODO: (done)\n",
    "            pred_softmax_all_ts, hdec_final = self.decoder(decoder_input, henc_final, henc_ts)\n",
    "\n",
    "        elif not teacher_enforce:\n",
    "            pred_softmax_all_ts = []\n",
    "            # TODO: (done)\n",
    "            decoder_input = torch.zeros(1, batch_size, self.decoder_vocabulary_size)\n",
    "            decoder_input[0, :, self.decoder_char_index[self.GO]] = 1.0\n",
    "\n",
    "            decoder_input = decoder_input.to(self.device)\n",
    "            hdec_init = henc_final\n",
    "            # iterate over all decoder stages\n",
    "            for _ in range(self.max_decoder_sequence_length):\n",
    "                # TODO: (done)\n",
    "                pred_softmax, hdec_final = self.decoder(decoder_input, hdec_init, henc_ts)\n",
    "                pred_softmax_all_ts.append(pred_softmax)\n",
    "                # convert softmax predictions to idx\n",
    "                preds_idx = pred_softmax.argmax(dim=2)\n",
    "                # convert idx predictions to one-hot encoding\n",
    "                decoder_input = torch.zeros(1, batch_size, self.decoder_vocabulary_size)\n",
    "                decoder_input = decoder_input.to(self.device)\n",
    "                decoder_input[0, np.arange(batch_size), preds_idx] = 1\n",
    "\n",
    "                # TODO: (done)\n",
    "                hdec_init = hdec_final\n",
    "                if inference:\n",
    "                    pred = preds_idx.squeeze().item()\n",
    "                    if pred == self.decoder_char_index[self.EOS]:\n",
    "                        break\n",
    "            pred_softmax_all_ts = torch.cat(pred_softmax_all_ts)\n",
    "\n",
    "        return pred_softmax_all_ts\n",
    "\n",
    "    def _train_on_batch(\n",
    "        self, encoder_input, target, teacher_forcing, decoder_input=None\n",
    "    ):\n",
    "        self.optimizer.zero_grad()\n",
    "        prediction = self.forward(\n",
    "            encoder_input, decoder_input=decoder_input, teacher_enforce=teacher_forcing\n",
    "        )\n",
    "        target_idx = target.argmax(2)\n",
    "        loss_on_batch = self.criterion(\n",
    "            prediction.reshape(-1, prediction.size()[2]), target_idx.reshape(-1)\n",
    "        )\n",
    "        loss_on_batch.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return loss_on_batch\n",
    "\n",
    "    def train(self, nb_epoch=10, batch_size=64, teacher_enforce=True):\n",
    "        arr = np.arange(self.encoder_input_tr.size()[1])\n",
    "        np.random.shuffle(arr)\n",
    "        nb_batch = int(self.encoder_input_tr.size()[1] / batch_size)\n",
    "        verbose_every = 5 if nb_batch >= 5 else 1\n",
    "\n",
    "        for epoch in range(nb_epoch):\n",
    "            self._reset_monitor_train_epoch()\n",
    "            if epoch > 0:\n",
    "                print()\n",
    "            for batch_idx in range(nb_batch):\n",
    "                idxs = arr[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "                encoder_input_batch_tr = self.encoder_input_tr[:, idxs, :]\n",
    "                target_batch_tr = self.target_tr[:, idxs, :]\n",
    "                decoder_input_batch_tr = self.decoder_input_tr[:, idxs, :]\n",
    "\n",
    "                batch_loss_tr = self._train_on_batch(\n",
    "                    encoder_input_batch_tr,\n",
    "                    target_batch_tr,\n",
    "                    teacher_forcing=teacher_enforce,\n",
    "                    decoder_input=decoder_input_batch_tr,\n",
    "                )\n",
    "                self._monitor_train_epoch(\n",
    "                    batch_loss=batch_loss_tr,\n",
    "                    batch_size=encoder_input_batch_tr.size()[1],\n",
    "                )\n",
    "\n",
    "                if (batch_idx + 1) % verbose_every == 0:\n",
    "                    self._display_training(\n",
    "                        epoch, nb_epoch, batch_idx, nb_batch, epoch_ended=False\n",
    "                    )\n",
    "\n",
    "            self._monitor_validation(teacher_enforce=teacher_enforce)\n",
    "            self._display_training(\n",
    "                epoch, nb_epoch, batch_idx, nb_batch, epoch_ended=True\n",
    "            )\n",
    "\n",
    "    def _monitor_train_epoch(self, batch_loss, batch_size):\n",
    "        self.total_loss += batch_loss * batch_size\n",
    "        self.total_loss_nb_samples += batch_size\n",
    "\n",
    "    def _reset_monitor_train_epoch(self):\n",
    "        self.total_loss = 0\n",
    "        self.total_loss_nb_samples = 0\n",
    "\n",
    "    def _monitor_validation(self, teacher_enforce):\n",
    "\n",
    "        prediction_val = self(\n",
    "            self.encoder_input_val,\n",
    "            decoder_input=self.decoder_input_val,\n",
    "            teacher_enforce=teacher_enforce,\n",
    "        )\n",
    "        target_val_idx = self.target_val.argmax(2)\n",
    "        self.last_loss_val = self.criterion(\n",
    "            prediction_val.reshape(-1, prediction_val.size()[2]),\n",
    "            target_val_idx.reshape(-1),\n",
    "        )\n",
    "\n",
    "    def _display_training(\n",
    "        self, epoch, nb_epoch, idx_batch, nb_batch, epoch_ended=False\n",
    "    ):\n",
    "        msg = \"Epoch {}/{} {} {}\".format(\n",
    "            epoch + 1,\n",
    "            nb_epoch,\n",
    "            utils.arrow(idx_batch + 1, nb_batch),\n",
    "            \" mean loss: %.5f\" % (self.total_loss.item() / self.total_loss_nb_samples),\n",
    "        )\n",
    "        if epoch_ended:\n",
    "            msg += \" val loss: %.5f\" % self.last_loss_val\n",
    "        print(msg, end=\"\\r\")\n",
    "\n",
    "    def _tensor_to_words(self, output, decoded=True):\n",
    "        dict_index_char = (\n",
    "            self.decoder_index_char if decoded else self.encoder_index_char\n",
    "        )\n",
    "        pred_idx = output.argmax(dim=2)\n",
    "        decoded_words = []\n",
    "        for seq in range(pred_idx.size()[1]):\n",
    "            idxs_chars = pred_idx[:, seq]\n",
    "            decoded_word = \"\".join(dict_index_char[idx.item()] for idx in idxs_chars)\n",
    "            if not decoded:\n",
    "                # correct errors due to zero vectors at the end\n",
    "                accepted_end_chars = set(list(\"0123456789\"))\n",
    "                for i in range(len(decoded_word) - 1, -1, -1):\n",
    "                    if decoded_word[i] in accepted_end_chars:\n",
    "                        decoded_word = decoded_word[: i + 1]\n",
    "                        break\n",
    "            decoded_words.append(decoded_word)\n",
    "        return decoded_words\n",
    "\n",
    "    def evaluate(self, nb=30):\n",
    "        nb = min(nb, self.encoder_input_val.size()[1])\n",
    "        for i in range(nb):\n",
    "            output = self(\n",
    "                self.encoder_input_val[:, i : i + 1, :],\n",
    "                inference=True,\n",
    "                teacher_enforce=False,\n",
    "            )\n",
    "            decoded_word = self._tensor_to_words(output, decoded=True)[0]\n",
    "            operation = self._tensor_to_words(\n",
    "                self.encoder_input_val[:, i : i + 1, :], decoded=False\n",
    "            )[0][::-1]\n",
    "            expected_decoded_word = self._tensor_to_words(\n",
    "                self.target_val[:, i : i + 1, :], decoded=True\n",
    "            )[0]\n",
    "            decoded_word = decoded_word.replace(\"\\n\", \"\")\n",
    "            operation = operation.replace(\"\\n\", \"\")\n",
    "            expected_decoded_word = expected_decoded_word.replace(\"\\n\", \"\")\n",
    "            print(\n",
    "                \"Input sentence: {} Decoded sentence: {} Expected decoded sentence: {}\".format(\n",
    "                    operation, decoded_word, expected_decoded_word\n",
    "                )\n",
    "            )\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Seq2seq(X, y, hidden_size=128, attention=False)\n",
    "b = torch.zeros(1, 10, a.decoder_vocabulary_size)\n",
    "b[0, :, a.decoder_char_index['=']] = 1.0\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no attention - teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2seq(X, y, hidden_size=128, attention=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 ==================================================>  mean loss: 0.76032 val loss: 0.62764\n",
      "Epoch 2/10 ==================================================>  mean loss: 0.59044 val loss: 0.57172\n",
      "Epoch 3/10 ==================================================>  mean loss: 0.55354 val loss: 0.54672\n",
      "Epoch 4/10 ==================================================>  mean loss: 0.53203 val loss: 0.52210\n",
      "Epoch 5/10 ==================================================>  mean loss: 0.50788 val loss: 0.50096\n",
      "Epoch 6/10 ==================================================>  mean loss: 0.48991 val loss: 0.48239\n",
      "Epoch 7/10 ==================================================>  mean loss: 0.47042 val loss: 0.46898\n",
      "Epoch 8/10 ==================================================>  mean loss: 0.45937 val loss: 0.46321\n",
      "Epoch 9/10 ==================================================>  mean loss: 0.46015 val loss: 0.46797\n",
      "Epoch 10/10 ==================================================>  mean loss: 0.44860 val loss: 0.45188\r"
     ]
    }
   ],
   "source": [
    "seq2seq.train(nb_epoch=10, batch_size=64, teacher_enforce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 409/411 Decoded sentence: 1.01176 Expected decoded sentence: 0.99513\n",
      "\n",
      "Input sentence: 51+563 Decoded sentence: 634 Expected decoded sentence: 614\n",
      "\n",
      "Input sentence: 711+280 Decoded sentence: 981 Expected decoded sentence: 991\n",
      "\n",
      "Input sentence: 738%383 Decoded sentence: 305 Expected decoded sentence: 355\n",
      "\n",
      "Input sentence: 210%939 Decoded sentence: 210 Expected decoded sentence: 210\n",
      "\n",
      "Input sentence: 665*970 Decoded sentence: 616550 Expected decoded sentence: 645050\n",
      "\n",
      "Input sentence: 234-930 Decoded sentence: -676 Expected decoded sentence: -696\n",
      "\n",
      "Input sentence: 275*226 Decoded sentence: 66370 Expected decoded sentence: 62150\n",
      "\n",
      "Input sentence: 781%988 Decoded sentence: 789 Expected decoded sentence: 781\n",
      "\n",
      "Input sentence: 372%398 Decoded sentence: 372 Expected decoded sentence: 372\n",
      "\n",
      "Input sentence: 36%658 Decoded sentence: 36 Expected decoded sentence: 36\n",
      "\n",
      "Input sentence: 288/911 Decoded sentence: 0.31685 Expected decoded sentence: 0.31614\n",
      "\n",
      "Input sentence: 922*781 Decoded sentence: 716692 Expected decoded sentence: 720082\n",
      "\n",
      "Input sentence: 513+143 Decoded sentence: 636 Expected decoded sentence: 656\n",
      "\n",
      "Input sentence: 610%806 Decoded sentence: 610 Expected decoded sentence: 610\n",
      "\n",
      "Input sentence: 436/841 Decoded sentence: 0.51555 Expected decoded sentence: 0.51843\n",
      "\n",
      "Input sentence: 407+906 Decoded sentence: 1293 Expected decoded sentence: 1313\n",
      "\n",
      "Input sentence: 848-529 Decoded sentence: 299 Expected decoded sentence: 319\n",
      "\n",
      "Input sentence: 558*756 Decoded sentence: 416168 Expected decoded sentence: 421848\n",
      "\n",
      "Input sentence: 825*952 Decoded sentence: 788030 Expected decoded sentence: 785400\n",
      "\n",
      "Input sentence: 238*558 Decoded sentence: 144436 Expected decoded sentence: 132804\n",
      "\n",
      "Input sentence: 401+795 Decoded sentence: 1186 Expected decoded sentence: 1196\n",
      "\n",
      "Input sentence: 29*421 Decoded sentence: 10579 Expected decoded sentence: 12209\n",
      "\n",
      "Input sentence: 193/352 Decoded sentence: 0.48979 Expected decoded sentence: 0.54830\n",
      "\n",
      "Input sentence: 79*270 Decoded sentence: 20370 Expected decoded sentence: 21330\n",
      "\n",
      "Input sentence: 35%505 Decoded sentence: 35 Expected decoded sentence: 35\n",
      "\n",
      "Input sentence: 159/301 Decoded sentence: 0.47106 Expected decoded sentence: 0.52824\n",
      "\n",
      "Input sentence: 656*306 Decoded sentence: 204776 Expected decoded sentence: 200736\n",
      "\n",
      "Input sentence: 342+415 Decoded sentence: 727 Expected decoded sentence: 757\n",
      "\n",
      "Input sentence: 488%330 Decoded sentence: 118 Expected decoded sentence: 158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no attention - no teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq = Seq2seq(X, y, hidden_size=128, attention=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 ==================================================>  mean loss: 0.80780 val loss: 0.68339\n",
      "Epoch 2/3 ==================================================>  mean loss: 0.62968 val loss: 0.61150\n",
      "Epoch 3/3 ==================================================>  mean loss: 0.58875 val loss: 0.58114\r"
     ]
    }
   ],
   "source": [
    "seq2seq.train(nb_epoch=3, batch_size=64, teacher_enforce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: 121-740 Decoded sentence: -649 Expected decoded sentence: -619\n",
      "\n",
      "Input sentence: 975*206 Decoded sentence: 212460 Expected decoded sentence: 200850\n",
      "\n",
      "Input sentence: 405%665 Decoded sentence: 405 Expected decoded sentence: 405\n",
      "\n",
      "Input sentence: 249/107 Decoded sentence: 2.51034 Expected decoded sentence: 2.32710\n",
      "\n",
      "Input sentence: 599+45 Decoded sentence: 644 Expected decoded sentence: 644\n",
      "\n",
      "Input sentence: 783/517 Decoded sentence: 1.69464 Expected decoded sentence: 1.51451\n",
      "\n",
      "Input sentence: 604%335 Decoded sentence: 11 Expected decoded sentence: 269\n",
      "\n",
      "Input sentence: 935-566 Decoded sentence: 329 Expected decoded sentence: 369\n",
      "\n",
      "Input sentence: 450-830 Decoded sentence: -340 Expected decoded sentence: -380\n",
      "\n",
      "Input sentence: 919+125 Decoded sentence: 1044 Expected decoded sentence: 1044\n",
      "\n",
      "Input sentence: 597%797 Decoded sentence: 597 Expected decoded sentence: 597\n",
      "\n",
      "Input sentence: 881+216 Decoded sentence: 1195 Expected decoded sentence: 1097\n",
      "\n",
      "Input sentence: 533-864 Decoded sentence: -303 Expected decoded sentence: -331\n",
      "\n",
      "Input sentence: 712%403 Decoded sentence: 211 Expected decoded sentence: 309\n",
      "\n",
      "Input sentence: 725%867 Decoded sentence: 725 Expected decoded sentence: 725\n",
      "\n",
      "Input sentence: 228+521 Decoded sentence: 773 Expected decoded sentence: 749\n",
      "\n",
      "Input sentence: 673+646 Decoded sentence: 1343 Expected decoded sentence: 1319\n",
      "\n",
      "Input sentence: 262%283 Decoded sentence: 262 Expected decoded sentence: 262\n",
      "\n",
      "Input sentence: 361/824 Decoded sentence: 0.49295 Expected decoded sentence: 0.43811\n",
      "\n",
      "Input sentence: 830%37 Decoded sentence: 2 Expected decoded sentence: 16\n",
      "\n",
      "Input sentence: 138/311 Decoded sentence: 0.41992 Expected decoded sentence: 0.44373\n",
      "\n",
      "Input sentence: 894/60 Decoded sentence: 12.26600 Expected decoded sentence: 14.90000\n",
      "\n",
      "Input sentence: 865*161 Decoded sentence: 151295 Expected decoded sentence: 139265\n",
      "\n",
      "Input sentence: 987+842 Decoded sentence: 1859 Expected decoded sentence: 1829\n",
      "\n",
      "Input sentence: 990*98 Decoded sentence: 85140 Expected decoded sentence: 97020\n",
      "\n",
      "Input sentence: 169%976 Decoded sentence: 169 Expected decoded sentence: 169\n",
      "\n",
      "Input sentence: 916%10 Decoded sentence: 6 Expected decoded sentence: 6\n",
      "\n",
      "Input sentence: 370/935 Decoded sentence: 0.33334 Expected decoded sentence: 0.39572\n",
      "\n",
      "Input sentence: 37/885 Decoded sentence: 0.01010 Expected decoded sentence: 0.04181\n",
      "\n",
      "Input sentence: 475*501 Decoded sentence: 226495 Expected decoded sentence: 237975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seq2seq.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attention - teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100000\n",
      "Number of unique encoder tokens: 15\n",
      "Number of unique decoder tokens: 14\n",
      "Max sequence length for encoding: 7\n",
      "Max sequence length for decoding: 11\n"
     ]
    }
   ],
   "source": [
    "seq2seq_attn = Seq2seq(X, y, hidden_size=128, attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 ==================================================>  mean loss: 0.82589 val loss: 0.71967\n",
      "Epoch 2/3 ==================================================>  mean loss: 0.69260\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 514.00 MiB (GPU 0; 8.00 GiB total capacity; 4.73 GiB already allocated; 8.25 MiB free; 1.17 GiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-055fdad87217>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mseq2seq_attn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mteacher_enforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-78-5818986025e2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, nb_epoch, batch_size, teacher_enforce)\u001b[0m\n\u001b[0;32m    263\u001b[0m                     )\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_monitor_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mteacher_enforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mteacher_enforce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m             self._display_training(\n\u001b[0;32m    267\u001b[0m                 \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_ended\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-78-5818986025e2>\u001b[0m in \u001b[0;36m_monitor_validation\u001b[1;34m(self, teacher_enforce)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_input_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m             \u001b[0mdecoder_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder_input_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m             \u001b[0mteacher_enforce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mteacher_enforce\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m         )\n\u001b[0;32m    285\u001b[0m         \u001b[0mtarget_val_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-78-5818986025e2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, encoder_input, decoder_input, teacher_enforce, inference)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mdecoder_input\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;31m# TODO: (done)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0mpred_softmax_all_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdec_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhenc_final\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhenc_ts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mteacher_enforce\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-73-b8a8cc36aa1d>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, decoder_input, hdec_init, henc_ts)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdec_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhenc_ts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# TODO: (done)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mhdec_ts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdec_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdec_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mhenc_ts\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    726\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    718\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[1;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maxim\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mrun_impl\u001b[1;34m(self, input, hx, batch_sizes)\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m             result = _VF.gru(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[1;32m--> 679\u001b[1;33m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    680\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 514.00 MiB (GPU 0; 8.00 GiB total capacity; 4.73 GiB already allocated; 8.25 MiB free; 1.17 GiB cached)"
     ]
    }
   ],
   "source": [
    "seq2seq_attn.train(nb_epoch=3, batch_size=64, teacher_enforce=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_attn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attention - no teacher forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_attn = Seq2seq(X, y, hidden_size=128, attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_attn.train(nb_epoch=3, batch_size=64, teacher_enforce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq_attn.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- 1) Explain the interest in using teacher forcing during training. What is specific about this process?\n",
    "\n",
    "When we don't use teacher forcing, the output of the decoder at a timestep is fed to the decoder's input at the next timestep. However, when the model isn't trained, the computed output is very bad. This means that the model needs to train while being given false inputs. It takes logically a lot more time to converge. With teacher forcing, we give, during training, the right input to the decoder instead of its previous output. With the perfectly right inputs, the model can learn much faster.\n",
    "\n",
    "Another huge avantage of teacher forcing is the fact that we don't need to compute the output at a timestep to start the next one. We just pass the inputs for all timesteps to the GRU model and it computes all outputs and the final hidden. This allows for better parallelization, and thus much faster forward pass.\n",
    "- 2) Describe step by step how the encoder-decoder couple works in this case (~ 5-10 lines)\n",
    "\n",
    "Here, the encoder takes a one-hot encode vector of all characters of the input sequence and computes a final hidden vector that summarizes the input sequence. In our case, we want this summary to somehow correspond to the result of the given calculation, as it is the only thing the decoder will see to produce the output. \n",
    "\n",
    "The decoder then takes this hidden vector and tries to output a sequence of characters that answers well the calculation of the input sequence. To do so, it uses the GRU unit at each timestep to compute a hidden vector. By feeding this vector to a Dense layer (matrix of parameters) and use a softmax operation on the result, we obtain a vector the size of our dictionary that contains the probability of each character. By taking the highest of these and zero the others, we obtain a one-hot encoded vector that corresponds to the character to print.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "- 1) Describe how the attention mechanism works in the seq2seq setting (~ 5-10 lines)\n",
    "\n",
    "The attention occurs at the decoder level. For each timesteps, we assign a weight to each of the encoder's hidden outputs by computing their similarity with the decoder's hidden output. This allows us to look at the input sequence during the decoding part, while choosing the right timesteps to focus on. \n",
    "- 2) Compare the perfomances of your model at inference time with and without attention mechanism. Do you see noticeable differences? Why?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
